{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drickkarmokar5776/-Classify-Vibration-Data/blob/main/vibration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "775OsmvJ2IDA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lceAFzOI1Z9s"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # Import numpy\n",
        "import pandas as pd  # Import pandas\n",
        "\n",
        "# Assuming data is loaded as a NumPy array from a file, like so:\n",
        "# other_data = np.load('other_data.npy')\n",
        "\n",
        "# Sample Float64 data (replace this with actual loading code)\n",
        "other_data = np.random.randn(1000, 10)  # 1000 samples, 10 features\n",
        "\n",
        "# Convert to DataFrame\n",
        "other_df = pd.DataFrame(other_data, columns=[f'Feature_{i}' for i in range(other_data.shape[1])])\n",
        "\n",
        "# Add labels (replace with actual labels)\n",
        "other_df['Label'] = np.random.randint(0, 12, size=len(other_df))\n",
        "\n",
        "# Save to CSV\n",
        "other_df.to_csv('other_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJO_BNnF1fH5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Example for loading Complex 128 data\n",
        "# Assuming data is loaded as a NumPy array from a file, like so:\n",
        "# S1_data = np.load('S1_data.npy')\n",
        "\n",
        "# Sample Complex128 data (replace this with actual loading code)\n",
        "S1_data = np.random.randn(1000) + 1j * np.random.randn(1000)\n",
        "\n",
        "# Convert to DataFrame with separate columns for real and imaginary parts\n",
        "S1_df = pd.DataFrame({\n",
        "    'Real_Part': S1_data.real,\n",
        "    'Imaginary_Part': S1_data.imag\n",
        "})\n",
        "\n",
        "# Add labels (replace with actual labels)\n",
        "# Assuming we have corresponding labels for each data point\n",
        "S1_df['Label'] = np.random.randint(0, 12, size=len(S1_df))\n",
        "\n",
        "# Save to CSV\n",
        "S1_df.to_csv('S1_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGEopZWp6O5O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load all the .dat files\n",
        "data1 = np.fromfile(\"/content/S10_train_10msps_1sec.dat\")\n",
        "data2 = np.fromfile(\"/content/S11_train_10msps_1sec.dat\")\n",
        "data3 = np.fromfile(\"/content/S2_train_10msps_1sec.dat\")\n",
        "data4 = np.fromfile(\"/content/S3_train_10msps_1sec.dat\")\n",
        "data5 = np.fromfile(\"/content/S4_train_10msps_1sec.dat\")\n",
        "data6 = np.fromfile(\"/content/S5_train_10msps_1sec.dat\")\n",
        "data7 = np.fromfile(\"/content/S6_train_10msps_1sec.dat\")\n",
        "data8 = np.fromfile(\"/content/S7_train_10msps_1sec.dat\")\n",
        "data9 = np.fromfile(\"/content/S8_data.dat\")\n",
        "data10 = np.fromfile(\"/content/S1_Data.dat\")\n",
        "data11 = np.fromfile(\"/content/S12_Data.dat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEt-0NLf6Clo"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert the numpy arrays to DataFrames\n",
        "df1 = pd.DataFrame(data1, columns=[\"S10_Vibration\"])\n",
        "df2 = pd.DataFrame(data2, columns=[\"S11_Vibration\"])\n",
        "df3 = pd.DataFrame(data3, columns=[\"S2_Vibration\"])\n",
        "df4 = pd.DataFrame(data4, columns=[\"S3_Vibration\"])\n",
        "df5 = pd.DataFrame(data5, columns=[\"S4_Vibration\"])\n",
        "df6 = pd.DataFrame(data6, columns=[\"S5_Vibration\"])\n",
        "df7 = pd.DataFrame(data7, columns=[\"S6_Vibration\"])\n",
        "df8 = pd.DataFrame(data8, columns=[\"S7_Vibration\"])\n",
        "df9 = pd.DataFrame(data9, columns=[\"S8_Vibration\"])\n",
        "df10 = pd.DataFrame(data10, columns=[\"S1_Vibration\"])\n",
        "df11 = pd.DataFrame(data11, columns=[\"S12_Vibration\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bryPDtyH_eTg"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply normalization to all DataFrames\n",
        "df1_scaled = pd.DataFrame(scaler.fit_transform(df1), columns=df1.columns)\n",
        "df2_scaled = pd.DataFrame(scaler.fit_transform(df2), columns=df2.columns)\n",
        "df3_scaled = pd.DataFrame(scaler.fit_transform(df3), columns=df3.columns)\n",
        "df4_scaled = pd.DataFrame(scaler.fit_transform(df4), columns=df4.columns)\n",
        "df5_scaled = pd.DataFrame(scaler.fit_transform(df5), columns=df5.columns)\n",
        "df6_scaled = pd.DataFrame(scaler.fit_transform(df6), columns=df6.columns)\n",
        "df7_scaled = pd.DataFrame(scaler.fit_transform(df7), columns=df7.columns)\n",
        "df8_scaled = pd.DataFrame(scaler.fit_transform(df8), columns=df8.columns)\n",
        "df9_scaled = pd.DataFrame(scaler.fit_transform(df9), columns=df9.columns)\n",
        "df10_scaled = pd.DataFrame(scaler.fit_transform(df10), columns=df10.columns)\n",
        "df11_scaled = pd.DataFrame(scaler.fit_transform(df11), columns=df11.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V_8VC08_gWa"
      },
      "outputs": [],
      "source": [
        "# Save the scaled datasets to CSV files\n",
        "df1_scaled.to_csv('/content/S10_scaled.csv', index=False)\n",
        "df2_scaled.to_csv('/content/S11_scaled.csv', index=False)\n",
        "df3_scaled.to_csv('/content/S2_scaled.csv', index=False)\n",
        "df4_scaled.to_csv('/content/S3_scaled.csv', index=False)\n",
        "df5_scaled.to_csv('/content/S4_scaled.csv', index=False)\n",
        "df6_scaled.to_csv('/content/S5_scaled.csv', index=False)\n",
        "df7_scaled.to_csv('/content/S6_scaled.csv', index=False)\n",
        "df8_scaled.to_csv('/content/S7_scaled.csv', index=False)\n",
        "df9_scaled.to_csv('/content/S8_scaled.csv', index=False)\n",
        "df10_scaled.to_csv('/content/S1_scaled.csv', index=False)\n",
        "df11_scaled.to_csv('/content/S12_scaled.csv', index=False)\n",
        "# Combine all scaled DataFrames into one (if desired)\n",
        "combined_df = pd.concat([df1_scaled, df2_scaled, df3_scaled, df4_scaled, df5_scaled,\n",
        "                         df6_scaled, df7_scaled, df8_scaled, df9_scaled, df10_scaled,\n",
        "                         df11_scaled], axis=0)\n",
        "\n",
        "# Save the combined data\n",
        "combined_df.to_csv('/content/combined_scaled_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye0m-4e6AoqD",
        "outputId": "dceeef37-133e-47a9-85cc-9f9d59125397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          S10_Vibration  S11_Vibration  S2_Vibration  S3_Vibration  \\\n",
            "0              0.860954            NaN           NaN           NaN   \n",
            "1              0.044116            NaN           NaN           NaN   \n",
            "2             -0.522496            NaN           NaN           NaN   \n",
            "3             -0.466300            NaN           NaN           NaN   \n",
            "4              0.388494            NaN           NaN           NaN   \n",
            "...                 ...            ...           ...           ...   \n",
            "14680059            NaN            NaN           NaN           NaN   \n",
            "14680060            NaN            NaN           NaN           NaN   \n",
            "14680061            NaN            NaN           NaN           NaN   \n",
            "14680062            NaN            NaN           NaN           NaN   \n",
            "14680063            NaN            NaN           NaN           NaN   \n",
            "\n",
            "          S4_Vibration  S5_Vibration  S6_Vibration  S7_Vibration  \\\n",
            "0                  NaN           NaN           NaN           NaN   \n",
            "1                  NaN           NaN           NaN           NaN   \n",
            "2                  NaN           NaN           NaN           NaN   \n",
            "3                  NaN           NaN           NaN           NaN   \n",
            "4                  NaN           NaN           NaN           NaN   \n",
            "...                ...           ...           ...           ...   \n",
            "14680059           NaN           NaN           NaN           NaN   \n",
            "14680060           NaN           NaN           NaN           NaN   \n",
            "14680061           NaN           NaN           NaN           NaN   \n",
            "14680062           NaN           NaN           NaN           NaN   \n",
            "14680063           NaN           NaN           NaN           NaN   \n",
            "\n",
            "          S8_Vibration  S1_Vibration  S12_Vibration  \n",
            "0                  NaN           NaN            NaN  \n",
            "1                  NaN           NaN            NaN  \n",
            "2                  NaN           NaN            NaN  \n",
            "3                  NaN           NaN            NaN  \n",
            "4                  NaN           NaN            NaN  \n",
            "...                ...           ...            ...  \n",
            "14680059           NaN           NaN       0.003269  \n",
            "14680060           NaN           NaN      -0.006503  \n",
            "14680061           NaN           NaN       0.000012  \n",
            "14680062           NaN           NaN       0.003269  \n",
            "14680063           NaN           NaN      -0.006503  \n",
            "\n",
            "[14680064 rows x 11 columns]\n",
            "   S10_Vibration  S11_Vibration  S2_Vibration  S3_Vibration  S4_Vibration  \\\n",
            "0       0.860954            NaN           NaN           NaN           NaN   \n",
            "1       0.044116            NaN           NaN           NaN           NaN   \n",
            "2      -0.522496            NaN           NaN           NaN           NaN   \n",
            "3      -0.466300            NaN           NaN           NaN           NaN   \n",
            "4       0.388494            NaN           NaN           NaN           NaN   \n",
            "\n",
            "   S5_Vibration  S6_Vibration  S7_Vibration  S8_Vibration  S1_Vibration  \\\n",
            "0           NaN           NaN           NaN           NaN           NaN   \n",
            "1           NaN           NaN           NaN           NaN           NaN   \n",
            "2           NaN           NaN           NaN           NaN           NaN   \n",
            "3           NaN           NaN           NaN           NaN           NaN   \n",
            "4           NaN           NaN           NaN           NaN           NaN   \n",
            "\n",
            "   S12_Vibration  \n",
            "0            NaN  \n",
            "1            NaN  \n",
            "2            NaN  \n",
            "3            NaN  \n",
            "4            NaN  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "combined_df = pd.read_csv('/content/combined_scaled_data.csv')\n",
        "\n",
        "# Print the contents of the DataFrame\n",
        "print(combined_df)\n",
        "# Print the first few rows of the DataFrame\n",
        "print(combined_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NOOaerGON27",
        "outputId": "97f39113-dea8-4c81-a537-82c7f5b0f921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Explained Variance Ratio of each component: [0.09090909 0.09090909]\n",
            "            PC1           PC2\n",
            "0  5.530605e-13  5.213550e-12\n",
            "1 -1.784692e-12 -2.327871e-12\n",
            "2  1.367488e-12  7.095554e-12\n",
            "3 -4.673110e-12  8.169196e-12\n",
            "4  4.217295e-12  2.981910e-12\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load your data from a CSV file\n",
        "data = pd.read_csv('/content/combined_scaled_data.csv')\n",
        "\n",
        "# Drop columns that are entirely NaN\n",
        "data = data.dropna(axis=1, how='all')\n",
        "\n",
        "# Handle missing values by imputation (filling NaN with mean)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "# Standardize the features (PCA is sensitive to the scale of the data)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(data_imputed)\n",
        "\n",
        "# Determine the number of components to keep\n",
        "n_components = min(X_scaled.shape[1], 2)  # Set to 2 or less, based on available features\n",
        "\n",
        "# Apply PCA to reduce dimensionality\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Optional: Create a DataFrame with the principal components\n",
        "pca_columns = [f'PC{i+1}' for i in range(X_pca.shape[1])]\n",
        "X_pca_df = pd.DataFrame(X_pca, columns=pca_columns)\n",
        "\n",
        "# Display the explained variance ratio of the principal components\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(\"Explained Variance Ratio of each component:\", explained_variance)\n",
        "\n",
        "# Display the resulting principal components\n",
        "print(X_pca_df.head())\n",
        "\n",
        "# If you want to save the PCA result to a CSV file:\n",
        "X_pca_df.to_csv('pca_output.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNmYAEPd56Pp",
        "outputId": "d089b19f-1e77-444d-fb6f-2d0da683a9f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            PC1           PC2  Cluster\n",
            "0  5.530605e-13  5.213550e-12        0\n",
            "1 -1.784692e-12 -2.327871e-12        0\n",
            "2  1.367488e-12  7.095554e-12        0\n",
            "3 -4.673110e-12  8.169196e-12        0\n",
            "4  4.217295e-12  2.981910e-12        0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "\n",
        "# Load the PCA-transformed data\n",
        "X_pca_df = pd.read_csv('/content/pca_output.csv')\n",
        "\n",
        "# Perform k-Means clustering to create pseudo-labels\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)  # Assuming 2 clusters; adjust as needed\n",
        "pseudo_labels = kmeans.fit_predict(X_pca_df)\n",
        "\n",
        "# Add the pseudo-labels to the PCA DataFrame\n",
        "X_pca_df['Cluster'] = pseudo_labels\n",
        "\n",
        "# Optional: Display the first few rows of the DataFrame with the new cluster labels\n",
        "print(X_pca_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaSsPPD9-wTi",
        "outputId": "daa031ab-ad5b-4fbc-c221-c67ecb526ffb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the PCA-transformed data\n",
        "X_pca_df = pd.read_csv('/content/pca_output.csv')\n",
        "\n",
        "# Perform k-Means clustering to create pseudo-labels\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)  # Assuming 2 clusters; adjust as needed\n",
        "pseudo_labels = kmeans.fit_predict(X_pca_df)\n",
        "\n",
        "# Add the pseudo-labels to the PCA DataFrame\n",
        "X_pca_df['Cluster'] = pseudo_labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca_df.drop(columns=['Cluster']), X_pca_df['Cluster'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the k-NN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "print(\"k-NN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "nP7GLCBe_yga",
        "outputId": "63eee3c2-d756-42bc-b086-d8c2bb83db64"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_test_split' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-df7901b1e28d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Split the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pca_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pca_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train the k-NN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca_df.drop(columns=['Cluster']), X_pca_df['Cluster'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the k-NN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "print(\"k-NN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your PCA-transformed and clustered data\n",
        "X_pca_df = pd.read_csv('/content/pca_output.csv')\n",
        "\n",
        "# Assuming 'Cluster' is the target for SVM classification\n",
        "X = X_pca_df.drop(columns=['PS1'])\n",
        "y = X_pca_df['Cluster']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the SVM model\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# 1 Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "#.2 Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# 3 Classification Report\n",
        "class_report = classification_report(y_test, y_pred_svm)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "id": "5dVIqDhEmbLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZRFqkEfyZF34C9v1OuGRH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}